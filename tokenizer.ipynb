{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing MIDIs (data/new_grand_midi_noBPE): 100%|██████████| 7227/7227 [32:00<00:00,  3.76it/s]  \n",
      "Loading token files: 100%|██████████| 7227/7227 [01:12<00:00, 99.46it/s] \n",
      "Learning byte pair encoding: 100%|██████████| 292/292 [7:32:48<00:00, 93.04s/it, seq_len_variation=-25.02, avg_nb_token_combs=2.04, max_nb_token_combs=3]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of original lengths: 13456.084567474049\n",
      "Mean length after BPE: 10089.323875432527\n",
      "Variation from original: -25.02 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying BPE to dataset: 100%|██████████| 7227/7227 [2:37:02<00:00,  1.30s/it]   \n"
     ]
    }
   ],
   "source": [
    "# tokenize with BPE\n",
    "from miditok import REMI\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI(sos_eos=True)\n",
    "midi_paths = list(Path('data/new_grand_midi').glob('**/*.mid*'))\n",
    "\n",
    "# A validation method to discard MIDIs we do not want\n",
    "def midi_valid(midi) -> bool:\n",
    "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
    "        return False  # time signature different from 4/*, 4 beats per bar\n",
    "    if midi.max_tick < 10 * midi.ticks_per_beat:\n",
    "        return False  # this MIDI is too short\n",
    "    return True\n",
    "\n",
    "# Converts MIDI files to tokens saved as JSON files\n",
    "tokenizer.tokenize_midi_dataset(        \n",
    "    midi_paths,\n",
    "    Path('data/new_grand_midi_noBPE'),\n",
    "    midi_valid\n",
    ")\n",
    "\n",
    "# Learns the vocabulary with BPE\n",
    "tokenizer.learn_bpe(\n",
    "    'data/new_grand_midi_noBPE',\n",
    "    512,\n",
    "    'data/new_grand_midi_BPE'\n",
    ")\n",
    "\n",
    "# Converts the tokenized musics into tokens with BPE\n",
    "tokenizer.apply_bpe_to_dataset(Path('data/new_grand_midi_noBPE'), Path('data/new_grand_midi_BPE'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import REMI\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize without BPE\n",
    "from miditok import REMI\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI(special_tokens=)\n",
    "midi_paths = list(Path('Final_Project/Dataset').glob('**/*.mid*'))\n",
    "\n",
    "# A validation method to discard MIDIs we do not want\n",
    "def midi_valid(midi) -> bool:\n",
    "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
    "        return False  # time signature different from 4/*, 4 beats per bar\n",
    "    if midi.max_tick < 10 * midi.ticks_per_beat:\n",
    "        return False  # this MIDI is too short\n",
    "    return True\n",
    "\n",
    "# Converts MIDI files to tokens saved as JSON files\n",
    "tokenizer.tokenize_midi_dataset(        \n",
    "    midi_paths,\n",
    "    Path('Final_Project/combined_noBPE3'),\n",
    "    midi_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading token files: 100%|██████████| 1355/1355 [00:04<00:00, 296.29it/s]\n",
      "Learning byte pair encoding: 100%|██████████| 292/292 [1:24:43<00:00, 17.41s/it, seq_len_variation=-30.13, avg_nb_token_combs=2.50, max_nb_token_combs=3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of original lengths: 18138.439696760855\n",
      "Mean length after BPE: 12673.77050310131\n",
      "Variation from original: -30.13 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying BPE to dataset: 100%|██████████| 1355/1355 [18:36<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from miditok import REMI\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI(sos_eos=True)\n",
    "\n",
    "# Learns the vocabulary with BPE\n",
    "tokenizer.learn_bpe(\n",
    "    'Final_Project/combined_noBPE',\n",
    "    512,\n",
    "    'Final_Project/combined_BPE'\n",
    ")\n",
    "\n",
    "# Converts the tokenized musics into tokens with BPE\n",
    "tokenizer.apply_bpe_to_dataset(Path('Final_Project/combined_noBPE'), Path('Final_Project/combined_BPE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "path = 'clean/data/SMALL_2M/tokens_small_noBPE/'\n",
    "# Turns all the json files in a folder into numpy arrays\n",
    "def json_to_nparray(path):\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(path + filename) as f:\n",
    "                data = json.load(f)\n",
    "                np.save(path + filename[:-5], np.array(data))\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "json_to_nparray(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_tokens(path): # function to get all tokens from the datasets single .npy files and put them in one numpy array\n",
    "    to_shuffle = np.array(()) # to_shuffle aggregator for one piece\n",
    "    data = np.array(()) # data aggregator for one piece\n",
    "    piece_counter = 0\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.npy'):\n",
    "            to_shuffle = np.append(to_shuffle, np.load(path + filename, allow_pickle=True)[()])\n",
    "    np.random.shuffle(to_shuffle)\n",
    "    \n",
    "    for i in range(len(to_shuffle)):\n",
    "        data = np.append(data, 1)\n",
    "        data = np.append(data, to_shuffle[i].get('tokens'))\n",
    "        data = np.append(data, 2)\n",
    "        piece_counter += 1\n",
    "        \n",
    "    return data, piece_counter\n",
    "\n",
    "path = 'clean/data/SMALL_2M/tokens_small_BPE/'\n",
    "data, piece_counter = get_tokens(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(path): # function to get all tokens from the dataset and put them in a numpy array\n",
    "    to_shuffle = np.array(()) # to_shuffle aggregator for one piece\n",
    "    data = np.array(()) # data aggregator for one piece\n",
    "    piece_counter = 0\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.npy'):\n",
    "            to_shuffle = np.append(to_shuffle, np.load(path + filename, allow_pickle=True)[()])\n",
    "    np.random.shuffle(to_shuffle)\n",
    "    \n",
    "    for i in range(len(to_shuffle)):\n",
    "        data = np.append(data, 1)\n",
    "        for j in range(len(to_shuffle[i].get('tokens'))):\n",
    "            data = np.append(data, to_shuffle[i].get('tokens')[j])\n",
    "        data = np.append(data, 2)\n",
    "        piece_counter += 1\n",
    "        \n",
    "    return data, piece_counter\n",
    "\n",
    "path = 'clean/data/SMALL_2M/tokens_small_noBPE/'\n",
    "data, piece_counter = get_tokens(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2701932,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('clean/data/SMALL_2M/SMALL_2M_noBPE', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
