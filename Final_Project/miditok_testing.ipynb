{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import REMI\n",
    "from miditok.utils import get_midi_programs\n",
    "from miditoolkit import MidiFile\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and loads a MIDI\n",
    "tokenizer = REMI()  # using the default parameters, read the documentation to customize your tokenizer\n",
    "midi = MidiFile('Dataset/chopin/chp_op18.mid')\n",
    "\n",
    "# Converts MIDI to tokens, and back to a MIDI\n",
    "tokens = tokenizer(midi)  # automatically detects MIDIs and tokens before converting\n",
    "converted_back_midi = tokenizer(tokens, get_midi_programs(midi))  # PyTorch / Tensorflow / Numpy tensors supported\n",
    "# get path to processed data\n",
    "token_BPE_path = Path('Dataset_tokenized_BPE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_back_midi = tokenizer(\"MIDI-Unprocessed_01_R1_2006_01-09_ORIG_MID--AUDIO_01_R1_2006_01_Track01_wav.json\", get_midi_programs(midi))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts MIDI files to tokens saved as JSON files\n",
    "midi_paths = list(Path('Dataset').glob('**/*.mid'))\n",
    "\n",
    "tokenizer.tokenize_midi_dataset(midi_paths, Path('Dataset_tokenized'))\n",
    "\n",
    "# Constructs the vocabulary with BPE, from the tokenized files\n",
    "tokenizer.learn_bpe(\n",
    "    vocab_size=500,\n",
    "    tokens_paths=list(Path('Dataset_tokenized').glob(\"**/*.json\")),\n",
    "    start_from_empty_voc=False,\n",
    ")\n",
    "\n",
    "# Converts the tokenized musics into tokens with BPE\n",
    "tokenizer.apply_bpe_to_dataset(Path('Dataset_tokenized'), Path('Dataset_tokenized_BPE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import REMI\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI(special_tokens=[\"BOS\", \"EOS\"])\n",
    "midi_paths = list(Path('Final_Project', 'big_dataset').glob('**/*.mid'))\n",
    "\n",
    "# A validation method to discard MIDIs we do not want\n",
    "def midi_valid(midi) -> bool:\n",
    "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
    "        return False  # time signature different from 4/*, 4 beats per bar\n",
    "    if midi.max_tick < 10 * midi.ticks_per_beat:\n",
    "        return False  # this MIDI is too short\n",
    "    return True\n",
    "\n",
    "# Converts MIDI files to tokens saved as JSON files\n",
    "tokenizer.tokenize_midi_dataset(        # 2 velocity and 1 duration values\n",
    "    midi_paths,\n",
    "    Path('Final_Project', 'tokens_noBPE'),\n",
    "    midi_valid,\n",
    ")\n",
    "\n",
    "# Learns the vocabulary with BPE\n",
    "tokenizer.learn_bpe(\n",
    "    vocab_size=512,\n",
    "    tokens_paths=list(Path('Final_Project', 'tokens_noBPE').glob(\"**/*.json\")),\n",
    "    out_dir=Path('Final_Project', 'tokens_BPE'),\n",
    ")\n",
    "\n",
    "# Converts the tokenized musics into tokens with BPE\n",
    "tokenizer.apply_bpe_to_dataset(Path('Final_Project', 'tokens_noBPE'), Path('Final_Project', 'tokens_BPE'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4dc7ff763bccf8d187fcb6b4b66c3bdc5a17148cd281fe390abc7e32c62a720d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
